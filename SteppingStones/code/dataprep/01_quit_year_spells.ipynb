{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure source and output directories:\n",
    "src_dir = Path(\"/Users/luisg/Desktop/SteppingStones_Parent/RAIS/output/data/full/rj_sample\") \n",
    "out_dir = Path(\"/Users/luisg/Desktop/SteppingStones_Parent/SteppingStones/data/interim/quit_spells\")\n",
    "# Create output directory if it doesn't exist\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 files\n"
     ]
    }
   ],
   "source": [
    "# List all .dta files in the source directory\n",
    "dta_files = sorted(src_dir.glob(\"RAIS_*.dta\"))\n",
    "print(f\"Found {len(dta_files)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18595ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2006...\n",
      "  Selected 27526 unique workers.\n",
      "Processing year 2007...\n",
      "  Selected 32585 unique workers.\n",
      "Processing year 2008...\n",
      "  Selected 42996 unique workers.\n",
      "Processing year 2009...\n",
      "  Selected 38852 unique workers.\n",
      "Processing year 2010...\n",
      "  Selected 51703 unique workers.\n",
      "Processing year 2011...\n",
      "  Selected 60690 unique workers.\n",
      "Processing year 2012...\n",
      "  Selected 64584 unique workers.\n",
      "Processing year 2013...\n",
      "  Selected 65613 unique workers.\n",
      "Processing year 2014...\n",
      "  Selected 63900 unique workers.\n",
      "Processing year 2015...\n",
      "  Selected 48683 unique workers.\n",
      "Processing year 2016...\n",
      "  Selected 34505 unique workers.\n",
      "✅ Combined panel: 531,637 rows → /Users/luisg/Desktop/SteppingStones_Parent/SteppingStones/data/interim/quit_spells/RAIS_panel_quits.dta\n"
     ]
    }
   ],
   "source": [
    "# Process each year's data and build panel of unique quitters\n",
    "df_list = []\n",
    "\n",
    "rng  = np.random.default_rng(seed=123)\n",
    "\n",
    "for f in dta_files:\n",
    "    # Extract year from filename\n",
    "    year = re.search(r\"RAIS_(\\d{4})\\.dta\", f.name).group(1)\n",
    "    print(f\"Processing year {year}...\")\n",
    "    # Load data\n",
    "    df_year = pd.read_stata(f, convert_categoricals=False)\n",
    "    # Filter to quitters only (causadesli 20 or 21)\n",
    "    df_year['quit'] = ((df_year['causadesli']==20 )| (df_year['causadesli']==21)).astype(int)\n",
    "    # Keep only quitters\n",
    "    df_year = df_year[df_year['quit'] == 1].copy()\n",
    "    # Genenrate hourly average wage per month\n",
    "    df_year['remmedr_h'] = (df_year['remmedr'])/(df_year['horascontr']*4.348)\n",
    "    # Generate hourly total wage for december wage\n",
    "    df_year['remdezr_h'] = (df_year['remdezr'])/(df_year['horascontr']*4.348)\n",
    "    # Add random column for tie-breaking\n",
    "    df_year['_rand'] = rng.random(len(df_year))\n",
    "\n",
    "    # Select unique worker with max hours worked; if tie, max avg wage; if tie, random\n",
    "    worker_id  = df_year['PIS'] # Unique worker identifier\n",
    "    hours = df_year['horascontr'] # Hours worked\n",
    "    avg_w_h = df_year['remmedr_h'] # Average hourly wage\n",
    "    max_hours = hours.groupby(worker_id).transform('max') # identify max hours per worker\n",
    "    rank1 = hours.eq(max_hours) # boolean mask for max hours\n",
    "    max_avg_w_and_rank1 = avg_w_h.where(rank1).groupby(worker_id).transform('max') # max avg wage among max hours\n",
    "    rank2 = rank1 & avg_w_h.eq(max_avg_w_and_rank1) # boolean mask for max avg wage among max hours\n",
    "    idx = (\n",
    "    df_year.loc[rank2]\n",
    "      .groupby(worker_id[rank2])['_rand']   # <- use the column name here\n",
    "      .idxmax()) # index of selected rows\n",
    "      # Grab the winning rows\n",
    "    df_selected = df_year.loc[idx].copy() # selected unique quitters\n",
    "    df_selected['year'] = int(year) # add year column\n",
    "    df_list.append(df_selected) # append to list\n",
    "    print(f\"  Selected {len(df_selected)} unique workers.\") # log progress\n",
    "    # build panel AFTER the loop (faster)\n",
    "df_panel = pd.concat(df_list, ignore_index=True) # combine all years\n",
    "\n",
    "# 1) Drop helper\n",
    "if '_rand' in df_panel.columns:\n",
    "    df_panel.drop(columns='_rand', inplace=True)\n",
    "\n",
    "# 2) Replace +-inf from divisions\n",
    "df_panel.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 3) Drop columns that are entirely NaN (e.g., clascnae95 in some years)\n",
    "all_null_cols = [c for c in df_panel.columns if df_panel[c].isna().all()] # identify all-null columns\n",
    "if all_null_cols:\n",
    "    df_panel.drop(columns=all_null_cols, inplace=True)\n",
    "\n",
    "# 4) Coerce object columns to pure strings (Stata requires string-like)\n",
    "for c in df_panel.select_dtypes(include='object').columns:\n",
    "    df_panel[c] = df_panel[c].astype(str).where(df_panel[c].notna(), None)\n",
    "\n",
    "# 5) Pandas nullable integers (Int64) → float (to keep NaN)\n",
    "for c in df_panel.columns:\n",
    "    if str(df_panel[c].dtype) == 'Int64':\n",
    "        df_panel[c] = df_panel[c].astype('float64')\n",
    "\n",
    "# 6) Booleans → tiny ints\n",
    "for c in df_panel.select_dtypes(include='bool').columns:\n",
    "    df_panel[c] = df_panel[c].astype('int8')\n",
    "\n",
    "# Save with UTF-8 Stata format\n",
    "out_path = out_dir / \"RAIS_panel_quits.dta\" # output path\n",
    "df_panel.to_stata(out_path, write_index=False, version=119) # save as Stata file\n",
    "print(f\"✅ Combined panel: {len(df_panel):,} rows → {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb62cdf",
   "metadata": {},
   "source": [
    "OK. Oct 27 2025\n",
    "\n",
    "- created notebooks to select spells for active workers at year end \n",
    "- created notebbok to select spells for quits\n",
    "\n",
    "\n",
    "What needs to be done: \n",
    "\n",
    "1)  create index for firm quality: \n",
    "    - average wage over the years across all workers \n",
    "    - \n",
    "\n",
    "2)  Create code to find quiters of year t in end-of-year workers in t+1. \n",
    "    -   identify their destination firms\n",
    "    -   connect destination firms to origin firms\n",
    "    -   generate index of quality of destinations (average wages of destiantion firms)\n",
    "\n",
    "3)  Run analysis of destination firm quality on origin firm quality\n",
    "\n",
    "4) schedule meetings with advisors to talk about projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad9f11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef84b69",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
