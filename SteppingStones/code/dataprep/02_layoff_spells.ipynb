{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e78d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure source and output directories:\n",
    "src_dir = Path(\"/Users/luisg/Desktop/SteppingStones_Parent/RAIS/output/data/full/rj_sample\") \n",
    "out_dir = Path(\"/Users/luisg/Desktop/SteppingStones_Parent/SteppingStones/data/interim/layoff_spells\")\n",
    "# Create output directory if it doesn't exist\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c928203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 files\n"
     ]
    }
   ],
   "source": [
    "# List all .dta files in the source directory\n",
    "dta_files = sorted(src_dir.glob(\"RAIS_*.dta\"))\n",
    "print(f\"Found {len(dta_files)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8cedbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2006...\n",
      "  Selected 82356 unique workers.\n",
      "Processing year 2007...\n",
      "  Selected 89625 unique workers.\n",
      "Processing year 2008...\n",
      "  Selected 103109 unique workers.\n",
      "Processing year 2009...\n",
      "  Selected 106544 unique workers.\n",
      "Processing year 2010...\n",
      "  Selected 112244 unique workers.\n",
      "Processing year 2011...\n",
      "  Selected 119454 unique workers.\n",
      "Processing year 2012...\n",
      "  Selected 123796 unique workers.\n",
      "Processing year 2013...\n",
      "  Selected 129232 unique workers.\n",
      "Processing year 2014...\n",
      "  Selected 131394 unique workers.\n",
      "Processing year 2015...\n",
      "  Selected 126811 unique workers.\n",
      "Processing year 2016...\n",
      "  Selected 115067 unique workers.\n",
      "✅ Combined panel: 1,239,632 rows → /Users/luisg/Desktop/SteppingStones_Parent/SteppingStones/data/interim/layoff_spells/RAIS_panel_layoffs.dta\n"
     ]
    }
   ],
   "source": [
    "# Process each year's data and build panel of unique laid off workers\n",
    "df_list = []\n",
    "\n",
    "rng  = np.random.default_rng(seed=123)\n",
    "\n",
    "for f in dta_files:\n",
    "    # Extract year from filename\n",
    "    year = re.search(r\"RAIS_(\\d{4})\\.dta\", f.name).group(1)\n",
    "    print(f\"Processing year {year}...\")\n",
    "    # Load data\n",
    "    df_year = pd.read_stata(f, convert_categoricals=False)\n",
    "    # Filter to laid off workers only (causadesli 10 or 11)\n",
    "    df_year['layoff'] = ((df_year['causadesli']==10 )| (df_year['causadesli']==11)).astype(int)\n",
    "    # Keep only laid off workers\n",
    "    df_year = df_year[df_year['layoff'] == 1].copy()\n",
    "    # Genenrate hourly average wage per month\n",
    "    df_year['remmedr_h'] = (df_year['remmedr'])/(df_year['horascontr']*4.348)\n",
    "    # Generate hourly total wage for december wage\n",
    "    df_year['remdezr_h'] = (df_year['remdezr'])/(df_year['horascontr']*4.348)\n",
    "    # Add random column for tie-breaking\n",
    "    df_year['_rand'] = rng.random(len(df_year))\n",
    "\n",
    "    # Select unique worker with max hours worked; if tie, max avg wage; if tie, random\n",
    "    worker_id  = df_year['PIS'] # Unique worker identifier\n",
    "    hours = df_year['horascontr'] # Hours worked\n",
    "    avg_w_h = df_year['remmedr_h'] # Average hourly wage\n",
    "    max_hours = hours.groupby(worker_id).transform('max') # identify max hours per worker\n",
    "    rank1 = hours.eq(max_hours) # boolean mask for max hours\n",
    "    max_avg_w_and_rank1 = avg_w_h.where(rank1).groupby(worker_id).transform('max') # max avg wage among max hours\n",
    "    rank2 = rank1 & avg_w_h.eq(max_avg_w_and_rank1) # boolean mask for max avg wage among max hours\n",
    "    idx = (\n",
    "    df_year.loc[rank2]\n",
    "      .groupby(worker_id[rank2])['_rand']   # <- use the column name here\n",
    "      .idxmax()) # index of selected rows\n",
    "      # Grab the winning rows\n",
    "    df_selected = df_year.loc[idx].copy() # selected unique quitters\n",
    "    df_selected['year'] = int(year) # add year column\n",
    "    df_list.append(df_selected) # append to list\n",
    "    print(f\"  Selected {len(df_selected)} unique workers.\") # log progress\n",
    "    # build panel AFTER the loop (faster)\n",
    "df_panel = pd.concat(df_list, ignore_index=True) # combine all years\n",
    "\n",
    "# 1) Drop helper\n",
    "if '_rand' in df_panel.columns:\n",
    "    df_panel.drop(columns='_rand', inplace=True)\n",
    "\n",
    "# 2) Replace +-inf from divisions\n",
    "df_panel.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 3) Drop columns that are entirely NaN (e.g., clascnae95 in some years)\n",
    "all_null_cols = [c for c in df_panel.columns if df_panel[c].isna().all()] # identify all-null columns\n",
    "if all_null_cols:\n",
    "    df_panel.drop(columns=all_null_cols, inplace=True)\n",
    "\n",
    "# 4) Coerce object columns to pure strings (Stata requires string-like)\n",
    "for c in df_panel.select_dtypes(include='object').columns:\n",
    "    df_panel[c] = df_panel[c].astype(str).where(df_panel[c].notna(), None)\n",
    "\n",
    "# 5) Pandas nullable integers (Int64) → float (to keep NaN)\n",
    "for c in df_panel.columns:\n",
    "    if str(df_panel[c].dtype) == 'Int64':\n",
    "        df_panel[c] = df_panel[c].astype('float64')\n",
    "\n",
    "# 6) Booleans → tiny ints\n",
    "for c in df_panel.select_dtypes(include='bool').columns:\n",
    "    df_panel[c] = df_panel[c].astype('int8')\n",
    "\n",
    "# Save with UTF-8 Stata format\n",
    "out_path = out_dir / \"RAIS_panel_layoffs.dta\" # output path\n",
    "df_panel.to_stata(out_path, write_index=False, version=119) # save as Stata file\n",
    "print(f\"✅ Combined panel: {len(df_panel):,} rows → {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
